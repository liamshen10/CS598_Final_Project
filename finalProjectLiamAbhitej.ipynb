{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBsq4mC17Zrq",
        "outputId": "bc95e47f-7472-45ed-89bf-988a00c350a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "# Install dependencies\n",
        "!pip install transformers\n",
        "!pip install nltk\n",
        "!pip install scikit-learn\n",
        "!pip install torch\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup spaCy\n",
        "!pip install -U spacy\n",
        "import spacy\n",
        "\n",
        "# Download English tokenizer model\n",
        "!python -m spacy download en_core_web_sm\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7QknFwe-AAy",
        "outputId": "bd48a8e1-93b5-4848-fec8-5d340bbf1df4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.15.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.11.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.13.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.4.26)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m79.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "X03D2PJn8Vou",
        "outputId": "77bbc461-9833-4465-cc3f-677dca597793"
      },
      "execution_count": 5,
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7dce9641-ab04-4b22-9911-3e46a23965ba\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-7dce9641-ab04-4b22-9911-3e46a23965ba\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-72edf3658aa1>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m(target_dir)\u001b[0m\n\u001b[1;32m     70\u001b[0m   \"\"\"\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'action'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'complete'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m     result = _output.eval_js(\n\u001b[0m\u001b[1;32m    173\u001b[0m         'google.colab._files._uploadFilesContinue(\"{output_id}\")'.format(\n\u001b[1;32m    174\u001b[0m             \u001b[0moutput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1 - Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from sklearn.metrics import classification_report, roc_auc_score, precision_recall_fscore_support\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "nltk.download('punkt')\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.metrics import roc_curve, auc, precision_recall_curve"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7HXFIwt7w8f",
        "outputId": "90d6ba4e-602a-456a-8222-57a7de6b6aeb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and clean header\n",
        "notes_df = pd.read_csv(\"sample10000.csv\")\n",
        "\n",
        "# Load other files\n",
        "diagnoses_df = pd.read_csv(\"diagnoses_icd.csv\")\n",
        "admissions_df = pd.read_csv(\"admissions.csv\", parse_dates=[\"ADMITTIME\", \"DISCHTIME\"])\n",
        "\n",
        "# Ensure CHARTTIME is datetime\n",
        "notes_df[\"CHARTTIME\"] = pd.to_datetime(notes_df[\"CHARTTIME\"])\n",
        "\n",
        "\n",
        "# Merge to get admission/discharge window\n",
        "merged_df = pd.merge(notes_df, admissions_df[[\"HADM_ID\", \"ADMITTIME\", \"DISCHTIME\"]],\n",
        "                     left_on=\"HADM_ID\", right_on=\"HADM_ID\", how=\"inner\")\n",
        "\n",
        "# Simulate CHARTTIME if missing or null\n",
        "def simulate_charttime(row):\n",
        "    if pd.notnull(row[\"ADMITTIME\"]) and pd.notnull(row[\"DISCHTIME\"]):\n",
        "        return row[\"ADMITTIME\"] + (row[\"DISCHTIME\"] - row[\"ADMITTIME\"]) * np.random.rand()\n",
        "    return pd.NaT\n",
        "\n",
        "merged_df[\"CHARTTIME\"] = merged_df.apply(simulate_charttime, axis=1)\n",
        "\n",
        "filtered_notes = merged_df[\n",
        "    (merged_df[\"CHARTTIME\"] >= merged_df[\"ADMITTIME\"]) &\n",
        "    (merged_df[\"CHARTTIME\"] <= merged_df[\"DISCHTIME\"])\n",
        "][[\"SUBJECT_ID\", \"HADM_ID\", \"CHARTTIME\", \"TEXT\"]].reset_index(drop=True).iloc[:1000]\n",
        "\n",
        "\n",
        "print(filtered_notes)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frQIKQ9f8U3G",
        "outputId": "5df3ac5f-3a11-45ae-e378-6aa78c2f33c0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     SUBJECT_ID  HADM_ID                     CHARTTIME  \\\n",
            "0         22532   167853 2151-07-25 20:14:44.678075742   \n",
            "1         13702   107527 2118-06-07 23:25:40.351525092   \n",
            "2         13702   167118 2119-05-18 22:10:39.036324439   \n",
            "3         13702   196489 2124-07-28 03:41:41.477604415   \n",
            "4         26880   135453 2162-03-10 12:29:25.456240980   \n",
            "..          ...      ...                           ...   \n",
            "995       15198   137838 2184-10-21 07:00:28.151380541   \n",
            "996        2712   198266 2101-02-12 07:31:01.764739907   \n",
            "997        2712   157537 2103-07-18 06:04:59.855792922   \n",
            "998       18511   123903 2191-03-03 05:02:30.455869792   \n",
            "999       76558   186116 2157-12-02 02:30:54.011481652   \n",
            "\n",
            "                                                  TEXT  \n",
            "0    Admission Date:  [**2151-7-16**]       Dischar...  \n",
            "1    Admission Date:  [**2118-6-2**]       Discharg...  \n",
            "2    Admission Date:  [**2119-5-4**]              D...  \n",
            "3    Admission Date:  [**2124-7-21**]              ...  \n",
            "4    Admission Date:  [**2162-3-3**]              D...  \n",
            "..                                                 ...  \n",
            "995  Admission Date:  [**2184-10-14**]       Discha...  \n",
            "996  Admission Date:  [**2101-2-10**]              ...  \n",
            "997  Admission Date:  [**2103-7-17**]              ...  \n",
            "998  Admission Date:  [**2191-2-23**]              ...  \n",
            "999  Admission Date:  [**2157-12-1**]              ...  \n",
            "\n",
            "[1000 rows x 4 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import pandas as pd\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def split_into_sentences_spacy(df):\n",
        "    sentence_data = []\n",
        "    texts = df['TEXT'].fillna('').tolist()  # Replace NaN with empty string\n",
        "    hadm_ids = df['HADM_ID'].tolist()\n",
        "\n",
        "    # Batch process texts using nlp.pipe\n",
        "    for idx, (doc, hadm_id) in enumerate(zip(nlp.pipe(texts, batch_size=32, n_process=1), hadm_ids)):\n",
        "        print(f\"Processing row {idx}\")\n",
        "        for sent in doc.sents:\n",
        "            sentence_data.append({\n",
        "                \"HADM_ID\": hadm_id,\n",
        "                \"sentence\": sent.text.strip()\n",
        "            })\n",
        "    return pd.DataFrame(sentence_data)\n",
        "\n",
        "sentences_df = split_into_sentences_spacy(filtered_notes)\n",
        "print(sentences_df)\n"
      ],
      "metadata": {
        "id": "LdT_M_0HI5Id",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9200139d-a600-4c17-bde2-98f69fb2b94d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing row 0\n",
            "Processing row 1\n",
            "Processing row 2\n",
            "Processing row 3\n",
            "Processing row 4\n",
            "Processing row 5\n",
            "Processing row 6\n",
            "Processing row 7\n",
            "Processing row 8\n",
            "Processing row 9\n",
            "Processing row 10\n",
            "Processing row 11\n",
            "Processing row 12\n",
            "Processing row 13\n",
            "Processing row 14\n",
            "Processing row 15\n",
            "Processing row 16\n",
            "Processing row 17\n",
            "Processing row 18\n",
            "Processing row 19\n",
            "Processing row 20\n",
            "Processing row 21\n",
            "Processing row 22\n",
            "Processing row 23\n",
            "Processing row 24\n",
            "Processing row 25\n",
            "Processing row 26\n",
            "Processing row 27\n",
            "Processing row 28\n",
            "Processing row 29\n",
            "Processing row 30\n",
            "Processing row 31\n",
            "Processing row 32\n",
            "Processing row 33\n",
            "Processing row 34\n",
            "Processing row 35\n",
            "Processing row 36\n",
            "Processing row 37\n",
            "Processing row 38\n",
            "Processing row 39\n",
            "Processing row 40\n",
            "Processing row 41\n",
            "Processing row 42\n",
            "Processing row 43\n",
            "Processing row 44\n",
            "Processing row 45\n",
            "Processing row 46\n",
            "Processing row 47\n",
            "Processing row 48\n",
            "Processing row 49\n",
            "Processing row 50\n",
            "Processing row 51\n",
            "Processing row 52\n",
            "Processing row 53\n",
            "Processing row 54\n",
            "Processing row 55\n",
            "Processing row 56\n",
            "Processing row 57\n",
            "Processing row 58\n",
            "Processing row 59\n",
            "Processing row 60\n",
            "Processing row 61\n",
            "Processing row 62\n",
            "Processing row 63\n",
            "Processing row 64\n",
            "Processing row 65\n",
            "Processing row 66\n",
            "Processing row 67\n",
            "Processing row 68\n",
            "Processing row 69\n",
            "Processing row 70\n",
            "Processing row 71\n",
            "Processing row 72\n",
            "Processing row 73\n",
            "Processing row 74\n",
            "Processing row 75\n",
            "Processing row 76\n",
            "Processing row 77\n",
            "Processing row 78\n",
            "Processing row 79\n",
            "Processing row 80\n",
            "Processing row 81\n",
            "Processing row 82\n",
            "Processing row 83\n",
            "Processing row 84\n",
            "Processing row 85\n",
            "Processing row 86\n",
            "Processing row 87\n",
            "Processing row 88\n",
            "Processing row 89\n",
            "Processing row 90\n",
            "Processing row 91\n",
            "Processing row 92\n",
            "Processing row 93\n",
            "Processing row 94\n",
            "Processing row 95\n",
            "Processing row 96\n",
            "Processing row 97\n",
            "Processing row 98\n",
            "Processing row 99\n",
            "Processing row 100\n",
            "Processing row 101\n",
            "Processing row 102\n",
            "Processing row 103\n",
            "Processing row 104\n",
            "Processing row 105\n",
            "Processing row 106\n",
            "Processing row 107\n",
            "Processing row 108\n",
            "Processing row 109\n",
            "Processing row 110\n",
            "Processing row 111\n",
            "Processing row 112\n",
            "Processing row 113\n",
            "Processing row 114\n",
            "Processing row 115\n",
            "Processing row 116\n",
            "Processing row 117\n",
            "Processing row 118\n",
            "Processing row 119\n",
            "Processing row 120\n",
            "Processing row 121\n",
            "Processing row 122\n",
            "Processing row 123\n",
            "Processing row 124\n",
            "Processing row 125\n",
            "Processing row 126\n",
            "Processing row 127\n",
            "Processing row 128\n",
            "Processing row 129\n",
            "Processing row 130\n",
            "Processing row 131\n",
            "Processing row 132\n",
            "Processing row 133\n",
            "Processing row 134\n",
            "Processing row 135\n",
            "Processing row 136\n",
            "Processing row 137\n",
            "Processing row 138\n",
            "Processing row 139\n",
            "Processing row 140\n",
            "Processing row 141\n",
            "Processing row 142\n",
            "Processing row 143\n",
            "Processing row 144\n",
            "Processing row 145\n",
            "Processing row 146\n",
            "Processing row 147\n",
            "Processing row 148\n",
            "Processing row 149\n",
            "Processing row 150\n",
            "Processing row 151\n",
            "Processing row 152\n",
            "Processing row 153\n",
            "Processing row 154\n",
            "Processing row 155\n",
            "Processing row 156\n",
            "Processing row 157\n",
            "Processing row 158\n",
            "Processing row 159\n",
            "Processing row 160\n",
            "Processing row 161\n",
            "Processing row 162\n",
            "Processing row 163\n",
            "Processing row 164\n",
            "Processing row 165\n",
            "Processing row 166\n",
            "Processing row 167\n",
            "Processing row 168\n",
            "Processing row 169\n",
            "Processing row 170\n",
            "Processing row 171\n",
            "Processing row 172\n",
            "Processing row 173\n",
            "Processing row 174\n",
            "Processing row 175\n",
            "Processing row 176\n",
            "Processing row 177\n",
            "Processing row 178\n",
            "Processing row 179\n",
            "Processing row 180\n",
            "Processing row 181\n",
            "Processing row 182\n",
            "Processing row 183\n",
            "Processing row 184\n",
            "Processing row 185\n",
            "Processing row 186\n",
            "Processing row 187\n",
            "Processing row 188\n",
            "Processing row 189\n",
            "Processing row 190\n",
            "Processing row 191\n",
            "Processing row 192\n",
            "Processing row 193\n",
            "Processing row 194\n",
            "Processing row 195\n",
            "Processing row 196\n",
            "Processing row 197\n",
            "Processing row 198\n",
            "Processing row 199\n",
            "Processing row 200\n",
            "Processing row 201\n",
            "Processing row 202\n",
            "Processing row 203\n",
            "Processing row 204\n",
            "Processing row 205\n",
            "Processing row 206\n",
            "Processing row 207\n",
            "Processing row 208\n",
            "Processing row 209\n",
            "Processing row 210\n",
            "Processing row 211\n",
            "Processing row 212\n",
            "Processing row 213\n",
            "Processing row 214\n",
            "Processing row 215\n",
            "Processing row 216\n",
            "Processing row 217\n",
            "Processing row 218\n",
            "Processing row 219\n",
            "Processing row 220\n",
            "Processing row 221\n",
            "Processing row 222\n",
            "Processing row 223\n",
            "Processing row 224\n",
            "Processing row 225\n",
            "Processing row 226\n",
            "Processing row 227\n",
            "Processing row 228\n",
            "Processing row 229\n",
            "Processing row 230\n",
            "Processing row 231\n",
            "Processing row 232\n",
            "Processing row 233\n",
            "Processing row 234\n",
            "Processing row 235\n",
            "Processing row 236\n",
            "Processing row 237\n",
            "Processing row 238\n",
            "Processing row 239\n",
            "Processing row 240\n",
            "Processing row 241\n",
            "Processing row 242\n",
            "Processing row 243\n",
            "Processing row 244\n",
            "Processing row 245\n",
            "Processing row 246\n",
            "Processing row 247\n",
            "Processing row 248\n",
            "Processing row 249\n",
            "Processing row 250\n",
            "Processing row 251\n",
            "Processing row 252\n",
            "Processing row 253\n",
            "Processing row 254\n",
            "Processing row 255\n",
            "Processing row 256\n",
            "Processing row 257\n",
            "Processing row 258\n",
            "Processing row 259\n",
            "Processing row 260\n",
            "Processing row 261\n",
            "Processing row 262\n",
            "Processing row 263\n",
            "Processing row 264\n",
            "Processing row 265\n",
            "Processing row 266\n",
            "Processing row 267\n",
            "Processing row 268\n",
            "Processing row 269\n",
            "Processing row 270\n",
            "Processing row 271\n",
            "Processing row 272\n",
            "Processing row 273\n",
            "Processing row 274\n",
            "Processing row 275\n",
            "Processing row 276\n",
            "Processing row 277\n",
            "Processing row 278\n",
            "Processing row 279\n",
            "Processing row 280\n",
            "Processing row 281\n",
            "Processing row 282\n",
            "Processing row 283\n",
            "Processing row 284\n",
            "Processing row 285\n",
            "Processing row 286\n",
            "Processing row 287\n",
            "Processing row 288\n",
            "Processing row 289\n",
            "Processing row 290\n",
            "Processing row 291\n",
            "Processing row 292\n",
            "Processing row 293\n",
            "Processing row 294\n",
            "Processing row 295\n",
            "Processing row 296\n",
            "Processing row 297\n",
            "Processing row 298\n",
            "Processing row 299\n",
            "Processing row 300\n",
            "Processing row 301\n",
            "Processing row 302\n",
            "Processing row 303\n",
            "Processing row 304\n",
            "Processing row 305\n",
            "Processing row 306\n",
            "Processing row 307\n",
            "Processing row 308\n",
            "Processing row 309\n",
            "Processing row 310\n",
            "Processing row 311\n",
            "Processing row 312\n",
            "Processing row 313\n",
            "Processing row 314\n",
            "Processing row 315\n",
            "Processing row 316\n",
            "Processing row 317\n",
            "Processing row 318\n",
            "Processing row 319\n",
            "Processing row 320\n",
            "Processing row 321\n",
            "Processing row 322\n",
            "Processing row 323\n",
            "Processing row 324\n",
            "Processing row 325\n",
            "Processing row 326\n",
            "Processing row 327\n",
            "Processing row 328\n",
            "Processing row 329\n",
            "Processing row 330\n",
            "Processing row 331\n",
            "Processing row 332\n",
            "Processing row 333\n",
            "Processing row 334\n",
            "Processing row 335\n",
            "Processing row 336\n",
            "Processing row 337\n",
            "Processing row 338\n",
            "Processing row 339\n",
            "Processing row 340\n",
            "Processing row 341\n",
            "Processing row 342\n",
            "Processing row 343\n",
            "Processing row 344\n",
            "Processing row 345\n",
            "Processing row 346\n",
            "Processing row 347\n",
            "Processing row 348\n",
            "Processing row 349\n",
            "Processing row 350\n",
            "Processing row 351\n",
            "Processing row 352\n",
            "Processing row 353\n",
            "Processing row 354\n",
            "Processing row 355\n",
            "Processing row 356\n",
            "Processing row 357\n",
            "Processing row 358\n",
            "Processing row 359\n",
            "Processing row 360\n",
            "Processing row 361\n",
            "Processing row 362\n",
            "Processing row 363\n",
            "Processing row 364\n",
            "Processing row 365\n",
            "Processing row 366\n",
            "Processing row 367\n",
            "Processing row 368\n",
            "Processing row 369\n",
            "Processing row 370\n",
            "Processing row 371\n",
            "Processing row 372\n",
            "Processing row 373\n",
            "Processing row 374\n",
            "Processing row 375\n",
            "Processing row 376\n",
            "Processing row 377\n",
            "Processing row 378\n",
            "Processing row 379\n",
            "Processing row 380\n",
            "Processing row 381\n",
            "Processing row 382\n",
            "Processing row 383\n",
            "Processing row 384\n",
            "Processing row 385\n",
            "Processing row 386\n",
            "Processing row 387\n",
            "Processing row 388\n",
            "Processing row 389\n",
            "Processing row 390\n",
            "Processing row 391\n",
            "Processing row 392\n",
            "Processing row 393\n",
            "Processing row 394\n",
            "Processing row 395\n",
            "Processing row 396\n",
            "Processing row 397\n",
            "Processing row 398\n",
            "Processing row 399\n",
            "Processing row 400\n",
            "Processing row 401\n",
            "Processing row 402\n",
            "Processing row 403\n",
            "Processing row 404\n",
            "Processing row 405\n",
            "Processing row 406\n",
            "Processing row 407\n",
            "Processing row 408\n",
            "Processing row 409\n",
            "Processing row 410\n",
            "Processing row 411\n",
            "Processing row 412\n",
            "Processing row 413\n",
            "Processing row 414\n",
            "Processing row 415\n",
            "Processing row 416\n",
            "Processing row 417\n",
            "Processing row 418\n",
            "Processing row 419\n",
            "Processing row 420\n",
            "Processing row 421\n",
            "Processing row 422\n",
            "Processing row 423\n",
            "Processing row 424\n",
            "Processing row 425\n",
            "Processing row 426\n",
            "Processing row 427\n",
            "Processing row 428\n",
            "Processing row 429\n",
            "Processing row 430\n",
            "Processing row 431\n",
            "Processing row 432\n",
            "Processing row 433\n",
            "Processing row 434\n",
            "Processing row 435\n",
            "Processing row 436\n",
            "Processing row 437\n",
            "Processing row 438\n",
            "Processing row 439\n",
            "Processing row 440\n",
            "Processing row 441\n",
            "Processing row 442\n",
            "Processing row 443\n",
            "Processing row 444\n",
            "Processing row 445\n",
            "Processing row 446\n",
            "Processing row 447\n",
            "Processing row 448\n",
            "Processing row 449\n",
            "Processing row 450\n",
            "Processing row 451\n",
            "Processing row 452\n",
            "Processing row 453\n",
            "Processing row 454\n",
            "Processing row 455\n",
            "Processing row 456\n",
            "Processing row 457\n",
            "Processing row 458\n",
            "Processing row 459\n",
            "Processing row 460\n",
            "Processing row 461\n",
            "Processing row 462\n",
            "Processing row 463\n",
            "Processing row 464\n",
            "Processing row 465\n",
            "Processing row 466\n",
            "Processing row 467\n",
            "Processing row 468\n",
            "Processing row 469\n",
            "Processing row 470\n",
            "Processing row 471\n",
            "Processing row 472\n",
            "Processing row 473\n",
            "Processing row 474\n",
            "Processing row 475\n",
            "Processing row 476\n",
            "Processing row 477\n",
            "Processing row 478\n",
            "Processing row 479\n",
            "Processing row 480\n",
            "Processing row 481\n",
            "Processing row 482\n",
            "Processing row 483\n",
            "Processing row 484\n",
            "Processing row 485\n",
            "Processing row 486\n",
            "Processing row 487\n",
            "Processing row 488\n",
            "Processing row 489\n",
            "Processing row 490\n",
            "Processing row 491\n",
            "Processing row 492\n",
            "Processing row 493\n",
            "Processing row 494\n",
            "Processing row 495\n",
            "Processing row 496\n",
            "Processing row 497\n",
            "Processing row 498\n",
            "Processing row 499\n",
            "Processing row 500\n",
            "Processing row 501\n",
            "Processing row 502\n",
            "Processing row 503\n",
            "Processing row 504\n",
            "Processing row 505\n",
            "Processing row 506\n",
            "Processing row 507\n",
            "Processing row 508\n",
            "Processing row 509\n",
            "Processing row 510\n",
            "Processing row 511\n",
            "Processing row 512\n",
            "Processing row 513\n",
            "Processing row 514\n",
            "Processing row 515\n",
            "Processing row 516\n",
            "Processing row 517\n",
            "Processing row 518\n",
            "Processing row 519\n",
            "Processing row 520\n",
            "Processing row 521\n",
            "Processing row 522\n",
            "Processing row 523\n",
            "Processing row 524\n",
            "Processing row 525\n",
            "Processing row 526\n",
            "Processing row 527\n",
            "Processing row 528\n",
            "Processing row 529\n",
            "Processing row 530\n",
            "Processing row 531\n",
            "Processing row 532\n",
            "Processing row 533\n",
            "Processing row 534\n",
            "Processing row 535\n",
            "Processing row 536\n",
            "Processing row 537\n",
            "Processing row 538\n",
            "Processing row 539\n",
            "Processing row 540\n",
            "Processing row 541\n",
            "Processing row 542\n",
            "Processing row 543\n",
            "Processing row 544\n",
            "Processing row 545\n",
            "Processing row 546\n",
            "Processing row 547\n",
            "Processing row 548\n",
            "Processing row 549\n",
            "Processing row 550\n",
            "Processing row 551\n",
            "Processing row 552\n",
            "Processing row 553\n",
            "Processing row 554\n",
            "Processing row 555\n",
            "Processing row 556\n",
            "Processing row 557\n",
            "Processing row 558\n",
            "Processing row 559\n",
            "Processing row 560\n",
            "Processing row 561\n",
            "Processing row 562\n",
            "Processing row 563\n",
            "Processing row 564\n",
            "Processing row 565\n",
            "Processing row 566\n",
            "Processing row 567\n",
            "Processing row 568\n",
            "Processing row 569\n",
            "Processing row 570\n",
            "Processing row 571\n",
            "Processing row 572\n",
            "Processing row 573\n",
            "Processing row 574\n",
            "Processing row 575\n",
            "Processing row 576\n",
            "Processing row 577\n",
            "Processing row 578\n",
            "Processing row 579\n",
            "Processing row 580\n",
            "Processing row 581\n",
            "Processing row 582\n",
            "Processing row 583\n",
            "Processing row 584\n",
            "Processing row 585\n",
            "Processing row 586\n",
            "Processing row 587\n",
            "Processing row 588\n",
            "Processing row 589\n",
            "Processing row 590\n",
            "Processing row 591\n",
            "Processing row 592\n",
            "Processing row 593\n",
            "Processing row 594\n",
            "Processing row 595\n",
            "Processing row 596\n",
            "Processing row 597\n",
            "Processing row 598\n",
            "Processing row 599\n",
            "Processing row 600\n",
            "Processing row 601\n",
            "Processing row 602\n",
            "Processing row 603\n",
            "Processing row 604\n",
            "Processing row 605\n",
            "Processing row 606\n",
            "Processing row 607\n",
            "Processing row 608\n",
            "Processing row 609\n",
            "Processing row 610\n",
            "Processing row 611\n",
            "Processing row 612\n",
            "Processing row 613\n",
            "Processing row 614\n",
            "Processing row 615\n",
            "Processing row 616\n",
            "Processing row 617\n",
            "Processing row 618\n",
            "Processing row 619\n",
            "Processing row 620\n",
            "Processing row 621\n",
            "Processing row 622\n",
            "Processing row 623\n",
            "Processing row 624\n",
            "Processing row 625\n",
            "Processing row 626\n",
            "Processing row 627\n",
            "Processing row 628\n",
            "Processing row 629\n",
            "Processing row 630\n",
            "Processing row 631\n",
            "Processing row 632\n",
            "Processing row 633\n",
            "Processing row 634\n",
            "Processing row 635\n",
            "Processing row 636\n",
            "Processing row 637\n",
            "Processing row 638\n",
            "Processing row 639\n",
            "Processing row 640\n",
            "Processing row 641\n",
            "Processing row 642\n",
            "Processing row 643\n",
            "Processing row 644\n",
            "Processing row 645\n",
            "Processing row 646\n",
            "Processing row 647\n",
            "Processing row 648\n",
            "Processing row 649\n",
            "Processing row 650\n",
            "Processing row 651\n",
            "Processing row 652\n",
            "Processing row 653\n",
            "Processing row 654\n",
            "Processing row 655\n",
            "Processing row 656\n",
            "Processing row 657\n",
            "Processing row 658\n",
            "Processing row 659\n",
            "Processing row 660\n",
            "Processing row 661\n",
            "Processing row 662\n",
            "Processing row 663\n",
            "Processing row 664\n",
            "Processing row 665\n",
            "Processing row 666\n",
            "Processing row 667\n",
            "Processing row 668\n",
            "Processing row 669\n",
            "Processing row 670\n",
            "Processing row 671\n",
            "Processing row 672\n",
            "Processing row 673\n",
            "Processing row 674\n",
            "Processing row 675\n",
            "Processing row 676\n",
            "Processing row 677\n",
            "Processing row 678\n",
            "Processing row 679\n",
            "Processing row 680\n",
            "Processing row 681\n",
            "Processing row 682\n",
            "Processing row 683\n",
            "Processing row 684\n",
            "Processing row 685\n",
            "Processing row 686\n",
            "Processing row 687\n",
            "Processing row 688\n",
            "Processing row 689\n",
            "Processing row 690\n",
            "Processing row 691\n",
            "Processing row 692\n",
            "Processing row 693\n",
            "Processing row 694\n",
            "Processing row 695\n",
            "Processing row 696\n",
            "Processing row 697\n",
            "Processing row 698\n",
            "Processing row 699\n",
            "Processing row 700\n",
            "Processing row 701\n",
            "Processing row 702\n",
            "Processing row 703\n",
            "Processing row 704\n",
            "Processing row 705\n",
            "Processing row 706\n",
            "Processing row 707\n",
            "Processing row 708\n",
            "Processing row 709\n",
            "Processing row 710\n",
            "Processing row 711\n",
            "Processing row 712\n",
            "Processing row 713\n",
            "Processing row 714\n",
            "Processing row 715\n",
            "Processing row 716\n",
            "Processing row 717\n",
            "Processing row 718\n",
            "Processing row 719\n",
            "Processing row 720\n",
            "Processing row 721\n",
            "Processing row 722\n",
            "Processing row 723\n",
            "Processing row 724\n",
            "Processing row 725\n",
            "Processing row 726\n",
            "Processing row 727\n",
            "Processing row 728\n",
            "Processing row 729\n",
            "Processing row 730\n",
            "Processing row 731\n",
            "Processing row 732\n",
            "Processing row 733\n",
            "Processing row 734\n",
            "Processing row 735\n",
            "Processing row 736\n",
            "Processing row 737\n",
            "Processing row 738\n",
            "Processing row 739\n",
            "Processing row 740\n",
            "Processing row 741\n",
            "Processing row 742\n",
            "Processing row 743\n",
            "Processing row 744\n",
            "Processing row 745\n",
            "Processing row 746\n",
            "Processing row 747\n",
            "Processing row 748\n",
            "Processing row 749\n",
            "Processing row 750\n",
            "Processing row 751\n",
            "Processing row 752\n",
            "Processing row 753\n",
            "Processing row 754\n",
            "Processing row 755\n",
            "Processing row 756\n",
            "Processing row 757\n",
            "Processing row 758\n",
            "Processing row 759\n",
            "Processing row 760\n",
            "Processing row 761\n",
            "Processing row 762\n",
            "Processing row 763\n",
            "Processing row 764\n",
            "Processing row 765\n",
            "Processing row 766\n",
            "Processing row 767\n",
            "Processing row 768\n",
            "Processing row 769\n",
            "Processing row 770\n",
            "Processing row 771\n",
            "Processing row 772\n",
            "Processing row 773\n",
            "Processing row 774\n",
            "Processing row 775\n",
            "Processing row 776\n",
            "Processing row 777\n",
            "Processing row 778\n",
            "Processing row 779\n",
            "Processing row 780\n",
            "Processing row 781\n",
            "Processing row 782\n",
            "Processing row 783\n",
            "Processing row 784\n",
            "Processing row 785\n",
            "Processing row 786\n",
            "Processing row 787\n",
            "Processing row 788\n",
            "Processing row 789\n",
            "Processing row 790\n",
            "Processing row 791\n",
            "Processing row 792\n",
            "Processing row 793\n",
            "Processing row 794\n",
            "Processing row 795\n",
            "Processing row 796\n",
            "Processing row 797\n",
            "Processing row 798\n",
            "Processing row 799\n",
            "Processing row 800\n",
            "Processing row 801\n",
            "Processing row 802\n",
            "Processing row 803\n",
            "Processing row 804\n",
            "Processing row 805\n",
            "Processing row 806\n",
            "Processing row 807\n",
            "Processing row 808\n",
            "Processing row 809\n",
            "Processing row 810\n",
            "Processing row 811\n",
            "Processing row 812\n",
            "Processing row 813\n",
            "Processing row 814\n",
            "Processing row 815\n",
            "Processing row 816\n",
            "Processing row 817\n",
            "Processing row 818\n",
            "Processing row 819\n",
            "Processing row 820\n",
            "Processing row 821\n",
            "Processing row 822\n",
            "Processing row 823\n",
            "Processing row 824\n",
            "Processing row 825\n",
            "Processing row 826\n",
            "Processing row 827\n",
            "Processing row 828\n",
            "Processing row 829\n",
            "Processing row 830\n",
            "Processing row 831\n",
            "Processing row 832\n",
            "Processing row 833\n",
            "Processing row 834\n",
            "Processing row 835\n",
            "Processing row 836\n",
            "Processing row 837\n",
            "Processing row 838\n",
            "Processing row 839\n",
            "Processing row 840\n",
            "Processing row 841\n",
            "Processing row 842\n",
            "Processing row 843\n",
            "Processing row 844\n",
            "Processing row 845\n",
            "Processing row 846\n",
            "Processing row 847\n",
            "Processing row 848\n",
            "Processing row 849\n",
            "Processing row 850\n",
            "Processing row 851\n",
            "Processing row 852\n",
            "Processing row 853\n",
            "Processing row 854\n",
            "Processing row 855\n",
            "Processing row 856\n",
            "Processing row 857\n",
            "Processing row 858\n",
            "Processing row 859\n",
            "Processing row 860\n",
            "Processing row 861\n",
            "Processing row 862\n",
            "Processing row 863\n",
            "Processing row 864\n",
            "Processing row 865\n",
            "Processing row 866\n",
            "Processing row 867\n",
            "Processing row 868\n",
            "Processing row 869\n",
            "Processing row 870\n",
            "Processing row 871\n",
            "Processing row 872\n",
            "Processing row 873\n",
            "Processing row 874\n",
            "Processing row 875\n",
            "Processing row 876\n",
            "Processing row 877\n",
            "Processing row 878\n",
            "Processing row 879\n",
            "Processing row 880\n",
            "Processing row 881\n",
            "Processing row 882\n",
            "Processing row 883\n",
            "Processing row 884\n",
            "Processing row 885\n",
            "Processing row 886\n",
            "Processing row 887\n",
            "Processing row 888\n",
            "Processing row 889\n",
            "Processing row 890\n",
            "Processing row 891\n",
            "Processing row 892\n",
            "Processing row 893\n",
            "Processing row 894\n",
            "Processing row 895\n",
            "Processing row 896\n",
            "Processing row 897\n",
            "Processing row 898\n",
            "Processing row 899\n",
            "Processing row 900\n",
            "Processing row 901\n",
            "Processing row 902\n",
            "Processing row 903\n",
            "Processing row 904\n",
            "Processing row 905\n",
            "Processing row 906\n",
            "Processing row 907\n",
            "Processing row 908\n",
            "Processing row 909\n",
            "Processing row 910\n",
            "Processing row 911\n",
            "Processing row 912\n",
            "Processing row 913\n",
            "Processing row 914\n",
            "Processing row 915\n",
            "Processing row 916\n",
            "Processing row 917\n",
            "Processing row 918\n",
            "Processing row 919\n",
            "Processing row 920\n",
            "Processing row 921\n",
            "Processing row 922\n",
            "Processing row 923\n",
            "Processing row 924\n",
            "Processing row 925\n",
            "Processing row 926\n",
            "Processing row 927\n",
            "Processing row 928\n",
            "Processing row 929\n",
            "Processing row 930\n",
            "Processing row 931\n",
            "Processing row 932\n",
            "Processing row 933\n",
            "Processing row 934\n",
            "Processing row 935\n",
            "Processing row 936\n",
            "Processing row 937\n",
            "Processing row 938\n",
            "Processing row 939\n",
            "Processing row 940\n",
            "Processing row 941\n",
            "Processing row 942\n",
            "Processing row 943\n",
            "Processing row 944\n",
            "Processing row 945\n",
            "Processing row 946\n",
            "Processing row 947\n",
            "Processing row 948\n",
            "Processing row 949\n",
            "Processing row 950\n",
            "Processing row 951\n",
            "Processing row 952\n",
            "Processing row 953\n",
            "Processing row 954\n",
            "Processing row 955\n",
            "Processing row 956\n",
            "Processing row 957\n",
            "Processing row 958\n",
            "Processing row 959\n",
            "Processing row 960\n",
            "Processing row 961\n",
            "Processing row 962\n",
            "Processing row 963\n",
            "Processing row 964\n",
            "Processing row 965\n",
            "Processing row 966\n",
            "Processing row 967\n",
            "Processing row 968\n",
            "Processing row 969\n",
            "Processing row 970\n",
            "Processing row 971\n",
            "Processing row 972\n",
            "Processing row 973\n",
            "Processing row 974\n",
            "Processing row 975\n",
            "Processing row 976\n",
            "Processing row 977\n",
            "Processing row 978\n",
            "Processing row 979\n",
            "Processing row 980\n",
            "Processing row 981\n",
            "Processing row 982\n",
            "Processing row 983\n",
            "Processing row 984\n",
            "Processing row 985\n",
            "Processing row 986\n",
            "Processing row 987\n",
            "Processing row 988\n",
            "Processing row 989\n",
            "Processing row 990\n",
            "Processing row 991\n",
            "Processing row 992\n",
            "Processing row 993\n",
            "Processing row 994\n",
            "Processing row 995\n",
            "Processing row 996\n",
            "Processing row 997\n",
            "Processing row 998\n",
            "Processing row 999\n",
            "        HADM_ID                                           sentence\n",
            "0        167853                                    Admission Date:\n",
            "1        167853              [**2151-7-16**]       Discharge Date:\n",
            "2        167853  [**2151-8-4**]\\n\\n\\nService:\\nADDENDUM:\\n\\nRAD...\n",
            "3        167853   This also\\nmoderate-sized left pleural effusion.\n",
            "4        167853  HEAD CT:  Head CT showed no intracranial hemor...\n",
            "...         ...                                                ...\n",
            "143564   186116   [**Last Name (STitle) 3649**] in\\nthe next week.\n",
            "143565   186116  Please call [**Telephone/Fax (1) 3070**] to sc...\n",
            "143566   186116  Please keep your previously scheduled appointm...\n",
            "143567   186116                                          Provider:\n",
            "143568   186116  [**First Name11 (Name Pattern1) **] [**Last Na...\n",
            "\n",
            "[143569 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Map hadm_id to ICD codes\n",
        "hadm_to_icd = diagnoses_df.groupby(\"HADM_ID\")[\"ICD9_CODE\"].apply(list).to_dict()\n",
        "\n",
        "# Attach ICDs\n",
        "sentences_df[\"labels\"] = sentences_df[\"HADM_ID\"].map(hadm_to_icd)\n",
        "\n",
        "# Drop unlabeled and explode to one ICD code per row\n",
        "sentences_df = sentences_df.dropna(subset=[\"labels\"])\n",
        "sentences_df = sentences_df.explode(\"labels\").reset_index(drop=True)\n",
        "print(len(sentences_df))\n"
      ],
      "metadata": {
        "id": "ELzpotshI7tG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac1506e7-c8ab-4917-b4ce-ae6bc9b3d7a4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1973548\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IZ2xKeW-YnLk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(diagnoses_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsb4tj4ZYqi0",
        "outputId": "e4c15a21-bf67-4e9a-b4c0-503398a36ab2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        ROW_ID  SUBJECT_ID  HADM_ID  SEQ_NUM ICD9_CODE\n",
            "0         1297         109   172335      1.0     40301\n",
            "1         1298         109   172335      2.0       486\n",
            "2         1299         109   172335      3.0     58281\n",
            "3         1300         109   172335      4.0      5855\n",
            "4         1301         109   172335      5.0      4254\n",
            "...        ...         ...      ...      ...       ...\n",
            "651042  639798       97503   188195      2.0     20280\n",
            "651043  639799       97503   188195      3.0     V5869\n",
            "651044  639800       97503   188195      4.0     V1279\n",
            "651045  639801       97503   188195      5.0      5275\n",
            "651046  639802       97503   188195      6.0      5569\n",
            "\n",
            "[651047 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SentenceDataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, label2idx):\n",
        "        self.sentences = dataframe[\"sentence\"].tolist()\n",
        "        self.labels = [label2idx[label] for label in dataframe[\"labels\"]]\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sentences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.sentences[idx]\n",
        "        inputs = self.tokenizer(text, truncation=True, padding=\"max_length\", max_length=128, return_tensors=\"pt\")\n",
        "        item = {key: val.squeeze() for key, val in inputs.items()}\n",
        "        item[\"label\"] = torch.tensor(self.labels[idx])\n",
        "        return item"
      ],
      "metadata": {
        "id": "yRP6DJRVJB2t"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ClinicalBertClassifier(nn.Module):\n",
        "    def __init__(self, num_labels):\n",
        "        super().__init__()\n",
        "        self.bert = AutoModel.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
        "        self.classifier = nn.Linear(self.bert.config.hidden_size, num_labels)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        cls_output = outputs.last_hidden_state[:, 0, :]\n",
        "        return self.classifier(cls_output)\n"
      ],
      "metadata": {
        "id": "cp2wQn_JJIqr"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build label index\n",
        "# Count label frequencies\n",
        "top_labels = sentences_df[\"labels\"].value_counts().nlargest(20).index\n",
        "\n",
        "# Keep only rows with these top labels\n",
        "sentences_df = sentences_df[sentences_df[\"labels\"].isin(top_labels)].reset_index(drop=True)\n",
        "\n",
        "# Rebuild label2idx since we reduced the label space\n",
        "label2idx = {label: idx for idx, label in enumerate(sorted(sentences_df[\"labels\"].unique()))}\n",
        "idx2label = {v: k for k, v in label2idx.items()}\n",
        "\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n"
      ],
      "metadata": {
        "id": "S9rrHJvcTPCk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2f7d4bc-4b3c-43a4-c516-5a541410b634"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "sampled_df = sentences_df.sample(n=1000, random_state=42).reset_index(drop=True)\n",
        "\n",
        "train_df, test_df = train_test_split(\n",
        "    sampled_df,\n",
        "    test_size=0.3,\n",
        "    stratify=sampled_df[\"labels\"],\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "train_df = train_df.sample(n=min(1000, len(train_df)), random_state=42).reset_index(drop=True)\n",
        "\n",
        "\n",
        "train_dataset = SentenceDataset(train_df, tokenizer, label2idx)\n",
        "test_dataset = SentenceDataset(test_df, tokenizer, label2idx)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=8)\n",
        "\n"
      ],
      "metadata": {
        "id": "yis1KdTcTGeJ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight=\"balanced\",\n",
        "    classes=np.array(list(label2idx.values())),\n",
        "    y=[label2idx[label] for label in train_df[\"labels\"]]\n",
        ")\n",
        "\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float)\n",
        "\n",
        "\n",
        "# Initialize model, optimizer, loss\n",
        "model = ClinicalBertClassifier(num_labels=len(label2idx))\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
        "loss_fn = nn.CrossEntropyLoss(weight=class_weights)\n",
        "\n",
        "# Training loop\n",
        "import time\n",
        "\n",
        "# Training loop with timing\n",
        "for epoch in range(3):\n",
        "    start_time = time.time()\n",
        "\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    print(len(train_loader))\n",
        "    for batch in train_loader:\n",
        "        print(len(batch))\n",
        "        input_ids = batch[\"input_ids\"]\n",
        "        attention_mask = batch[\"attention_mask\"]\n",
        "        labels = batch[\"label\"]\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(input_ids, attention_mask)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    elapsed = time.time() - start_time\n",
        "    print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}, Time: {elapsed:.2f} seconds\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1O0SnofLJJ-b",
        "outputId": "f798d224-303a-416e-9a80-c6c5c494da6f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 132.8522, Time: 521.84 seconds\n",
            "Epoch 2, Loss: 125.1680, Time: 509.90 seconds\n",
            "Epoch 3, Loss: 112.9669, Time: 501.92 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "y_true, y_pred = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        input_ids = batch[\"input_ids\"]\n",
        "        attention_mask = batch[\"attention_mask\"]\n",
        "        labels = batch[\"label\"].cpu().numpy()\n",
        "        logits = model(input_ids, attention_mask).cpu().numpy()\n",
        "        preds = logits.argmax(axis=1)\n",
        "\n",
        "        y_true.extend(labels)\n",
        "        y_pred.extend(preds)\n",
        "\n",
        "# Only evaluate on labels that exist in test set\n",
        "eval_labels = sorted(set(y_true + y_pred))\n",
        "target_names = [idx2label[idx] for idx in eval_labels]\n",
        "\n",
        "print(classification_report(y_true, y_pred, labels=eval_labels, target_names=target_names, zero_division=0))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cs94K6SZJOa7",
        "outputId": "3bebee15-363f-4673-d58f-ef8cedafda53"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        2449       0.00      0.00      0.00         8\n",
            "       25000       0.00      0.00      0.00        17\n",
            "        2720       0.00      0.00      0.00        13\n",
            "        2724       0.00      0.00      0.00        14\n",
            "        2762       0.00      0.00      0.00         7\n",
            "        2859       0.00      0.00      0.00         9\n",
            "        4019       0.12      0.03      0.04        38\n",
            "       40390       0.00      0.00      0.00        10\n",
            "       41401       0.06      0.06      0.06        17\n",
            "       42731       0.10      0.04      0.06        25\n",
            "        4280       0.25      0.06      0.10        32\n",
            "         486       0.00      0.00      0.00        14\n",
            "         496       0.07      0.18      0.10        11\n",
            "        5070       0.07      0.30      0.11        10\n",
            "       51881       0.09      0.06      0.07        17\n",
            "       53081       0.13      0.18      0.15        11\n",
            "        5849       0.00      0.00      0.00        20\n",
            "        5990       0.08      0.09      0.08        11\n",
            "       99592       0.00      0.00      0.00         8\n",
            "       V5861       0.09      0.25      0.13         8\n",
            "\n",
            "    accuracy                           0.05       300\n",
            "   macro avg       0.05      0.06      0.05       300\n",
            "weighted avg       0.07      0.05      0.05       300\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "model.eval()\n",
        "y_true, y_probs = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        input_ids = batch[\"input_ids\"]\n",
        "        attention_mask = batch[\"attention_mask\"]\n",
        "        labels = batch[\"label\"].cpu().numpy()\n",
        "        logits = model(input_ids, attention_mask).cpu().numpy()\n",
        "\n",
        "        probs = F.softmax(torch.tensor(logits), dim=1).numpy()\n",
        "\n",
        "        y_true.extend(labels)\n",
        "        y_probs.extend(probs)\n",
        "\n",
        "y_true = np.array(y_true)\n",
        "y_probs = np.array(y_probs)\n",
        "\n",
        "try:\n",
        "    auroc = roc_auc_score(y_true, y_probs, multi_class='ovr')\n",
        "    print(f\"\\nMulticlass AUROC (OVR): {auroc:.4f}\")\n",
        "except ValueError as e:\n",
        "    print(\"AUROC could not be computed:\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4_-8zv_rk4G",
        "outputId": "413ae7d1-1308-4b10-e4b4-f2826ff7620a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Multiclass AUROC (OVR): 0.4902\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModel\n",
        "import torch.nn as nn\n",
        "\n",
        "class ClinicalBertAvgPoolClassifier(nn.Module):\n",
        "    def __init__(self, num_labels):\n",
        "        super().__init__()\n",
        "        self.bert = AutoModel.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.classifier = nn.Linear(self.bert.config.hidden_size, num_labels)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        last_hidden_state = outputs.last_hidden_state  # shape: (batch_size, seq_len, hidden_size)\n",
        "\n",
        "        # Apply attention mask for average pooling\n",
        "        attention_mask = attention_mask.unsqueeze(-1)  # shape: (batch_size, seq_len, 1)\n",
        "        masked_embeddings = last_hidden_state * attention_mask\n",
        "        summed = masked_embeddings.sum(dim=1)\n",
        "        counts = attention_mask.sum(dim=1)\n",
        "        avg_pooled = summed / counts.clamp(min=1e-9)  # avoid division by zero\n",
        "\n",
        "        logits = self.classifier(self.dropout(avg_pooled))\n",
        "        return logits\n"
      ],
      "metadata": {
        "id": "3xJh2xuOcbVf"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight=\"balanced\",\n",
        "    classes=np.array(list(label2idx.values())),\n",
        "    y=[label2idx[label] for label in train_df[\"labels\"]]\n",
        ")\n",
        "\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float)\n",
        "\n",
        "\n",
        "# Initialize model, optimizer, loss\n",
        "model = ClinicalBertAvgPoolClassifier(num_labels=len(label2idx))\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
        "loss_fn = nn.CrossEntropyLoss(weight=class_weights)\n",
        "\n",
        "# Training loop\n",
        "import time\n",
        "\n",
        "# Training loop with timing\n",
        "for epoch in range(3):\n",
        "    start_time = time.time()\n",
        "\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    print(len(train_loader))\n",
        "    for batch in train_loader:\n",
        "        print(len(batch))\n",
        "        input_ids = batch[\"input_ids\"]\n",
        "        attention_mask = batch[\"attention_mask\"]\n",
        "        labels = batch[\"label\"]\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(input_ids, attention_mask)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    elapsed = time.time() - start_time\n",
        "    print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}, Time: {elapsed:.2f} seconds\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ErsMOmNluvEq",
        "outputId": "546c5235-9474-4d17-c25b-ecaecdae009c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 132.8941, Time: 516.45 seconds\n",
            "Epoch 2, Loss: 127.8139, Time: 505.54 seconds\n",
            "Epoch 3, Loss: 121.7167, Time: 512.59 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "model.eval()\n",
        "y_true, y_probs = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        input_ids = batch[\"input_ids\"]\n",
        "        attention_mask = batch[\"attention_mask\"]\n",
        "        labels = batch[\"label\"].cpu().numpy()\n",
        "        logits = model(input_ids, attention_mask).cpu().numpy()\n",
        "\n",
        "        probs = F.softmax(torch.tensor(logits), dim=1).numpy()\n",
        "\n",
        "        y_true.extend(labels)\n",
        "        y_probs.extend(probs)\n",
        "\n",
        "y_true = np.array(y_true)\n",
        "y_probs = np.array(y_probs)\n",
        "\n",
        "try:\n",
        "    auroc = roc_auc_score(y_true, y_probs, multi_class='ovr')\n",
        "    print(f\"\\nMulticlass AUROC (OVR): {auroc:.4f}\")\n",
        "except ValueError as e:\n",
        "    print(\"AUROC could not be computed:\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZr53luQuyj0",
        "outputId": "4feaf9de-8543-412b-f896-dbbad1fd45eb"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Multiclass AUROC (OVR): 0.4882\n"
          ]
        }
      ]
    }
  ]
}
